
<h1 align="center">ğŸ¤Ÿ Sign Language Detection Web App</h1>
<h3 align="center"> | Deep Learning Ã— Computer Vision Ã— Real-Time Browser App Ã— AI Sentence Generation |</h3>

<p align="center">
  <img src="https://komarev.com/ghpvc/?username=sign-lang-detection&label=PROJECT+VIEWS" alt="views" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Framework-Flask-blue?logo=flask" />
  <img src="https://img.shields.io/badge/Frontend-JavaScript-yellow?logo=javascript" />
  <img src="https://img.shields.io/badge/DeepLearning-TensorFlow-orange?logo=tensorflow" />
  <img src="https://img.shields.io/badge/AI-LangChainÃ—Groq-green?logo=OpenAI" />
</p>

---

## ğŸ“Œ Description

A web-based application that detects hand signs using a deep learning model **and converts recognized words into meaningful English sentences using LangChain + Groq AI.**

This project combines:
- ğŸ§  A trained CNN model for gesture recognition
- ğŸ’¬ LangChain + Groq LLM for intelligent sentence generation
- ğŸŒ A real-time browser-based interface built with Flask and JavaScript

---

## ğŸš€ Features

- ğŸ“· Real-time webcam gesture detection in browser  
- ğŸ¤– Pre-trained Keras model (`gesture_model.h5`) for ASL alphabets (Aâ€“Z)  
- ğŸ§  AI-powered **sentence generation** using LangChain and Groq LLM (`qwen/qwen3-32b`)  
- ğŸ”  Converts recognized signs into grammatically correct English sentences  
- ğŸ–¥ï¸ Clean frontend using HTML, CSS, and Vanilla JS  
- ğŸ” Flask-powered Python backend  

---

## ğŸ“ Project Structure

- ğŸ“„ **app.py** â€” Flask backend
- ğŸ“‚ **data/**
  - ğŸ“„ gestures_data.csv â€” Dataset used for training
- ğŸ“‚ **models/**
  - ğŸ§  gesture_model.h5 â€” Trained Keras model
  - ğŸ“ labels.json â€” Gesture-label mappings
- ğŸ“‚ **static/**
  - ğŸ“‚ css/
    - ğŸ¨ style.css â€” Custom styles
  - ğŸ“‚ js/
    - âœï¸ capture.js â€” Capture gesture data
    - ğŸ‘ï¸ detect.js â€” Real-time gesture detection
    - ğŸ› ï¸ train.js â€” Trigger training routines
- ğŸ“‚ **templates/**
  - ğŸ  index.html â€” Homepage
  - âœ‹ capture.html â€” Gesture capture interface
  - ğŸ§ª train.html â€” Model training interface
- ğŸ“ **venv/** â€” Python virtual environment (optional)



---

## ğŸ§  LangChain + Groq Integration

When the **â€œGenerate Sentenceâ€** button is clicked:
1. The recognized words are sent to the Flask backend.
2. Flask runs a **LangChain pipeline** with **Groqâ€™s Qwen model**.
3. The model interprets and converts the recognized words into a fluent English sentence.
4. The result is displayed in the â€œPossible Sentenceâ€ section on the UI.

Example:
Input: ["go", "school", tomorrow"]
Output: "I will go to school tomorrow."


---

## ğŸš€ Getting Started

### ğŸ”§ Installation

```bash
# Clone the repo
git clone https://github.com/yourusername/sign-language-detection.git
cd sign-language-detection

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate   # For Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt


â–¶ï¸ Run the App
python app.py

ğŸ“¦ Requirements
flask
tensorflow
numpy
mediapipe
opencv-python
pandas
scikit-learn
langchain-core
langchain-community
langchain-groq

ğŸ™‹â€â™‚ï¸ Author

Yuvraj Singh
ğŸ“§ vyuvrajsingh98@gmail.com

ğŸŒ https://github.com/Yuvrajj07






